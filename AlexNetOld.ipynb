{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import Functions\n",
    "import var\n",
    "import Viz\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to implementation using Keras](https://engmrk.com/alexnet-implementation-using-keras/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alexnet(dim):\n",
    "    #Instantiate an empty model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96, input_shape=dim, kernel_size=(11,11), strides=(4,4), padding='valid', \n",
    "                    activation = 'relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid', \n",
    "                    activation = 'relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', \n",
    "                    activation = 'relu'))\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid', \n",
    "                    activation = 'relu'))\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid', \n",
    "                    activation = 'relu'))\n",
    "    \n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "    # Passing it to a Fully Connected layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # 1st Fully Connected Layer\n",
    "    model.add(Dense(4096, input_shape=(227*227*3,), activation = 'relu'))\n",
    "    \n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 2nd Fully Connected Layer\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # 3rd Fully Connected Layer\n",
    "    model.add(Dense(1000, activation = 'relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = Functions.get_samples('alexnet')\n",
    "print(x_train.shape, x_test.shape) \n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = True \n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=30)\n",
    "model_checkpoint = ModelCheckpoint('../models/Alexnet-ModelCheckpointWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 5, mode = 'min')\n",
    "epochs = 2000\n",
    "batch_size = 16\n",
    "if var.img_type == 'grey': \n",
    "    dim = (var.alex_dimension[0], var.alex_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.alex_dimension[0], var.alex_dimension[1], 3)\n",
    "    \n",
    "alexnet = get_alexnet(dim =dim)\n",
    "\n",
    "if augment: \n",
    "    augmentation =ImageDataGenerator(rotation_range = 15, width_shift_range = .1, height_shift_range = .1, \n",
    "                                                           horizontal_flip = True, fill_mode = 'nearest')\n",
    "    augmentation.fit(x_train)\n",
    "    alexnet_history = alexnet.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "                epochs = epochs, steps_per_epoch = 8,\n",
    "         callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n",
    "else: \n",
    "    \n",
    "    alexnet_history = alexnet.fit(x_train, y_train, batch_size = batch_size,\n",
    "                epochs = epochs, \n",
    "         callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alexnet.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(alexnet_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 3)\n",
    "    \n",
    "    \n",
    "alexnet = get_alexnet(dim)\n",
    "alexnet.load_weights('../models/Alexnet-ModelCheckpointWeights.h5') #load the best weights before overfitting\n",
    "\n",
    "Viz.plot_roc_auc(alexnet, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 3)\n",
    "    \n",
    "    \n",
    "mobilenet = get_mobile_net(dim)\n",
    "mobilenet.load_weights('../models/MobileNet-ModelCheckpointWeights.h5') #load the best weights before overfitting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_prob = [np.argmax(i) for i in mobilenet.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "y_train_prob = [np.argmax(i) for i in mobilenet.predict(x_train)]\n",
    "y_train_labels = [np.argmax(i) for i in y_train]\n",
    "train_cnf = confusion_matrix(y_train_labels, y_train_prob)\n",
    "\n",
    "Viz.plot_model_cm(test_cnf, train_cnf, classes = ['No Weapon', 'Handgun', 'Rifle'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from lime import lime_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../Tests/Photos'\n",
    "if var.img_type == 'grey': \n",
    "    dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 3)\n",
    "    \n",
    "    \n",
    "mobilenet = get_mobile_net(dim)\n",
    "mobilenet.load_weights('../models/MobileNet-ModelCheckpointWeights.h5') #load the best weights before overfitting\n",
    "\n",
    "for file in os.listdir(base_path): \n",
    "    if file == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    full_path = f'{base_path}/{file}'\n",
    "    img = Functions.get_image_value(full_path, var.mobilenet_dimension, var.img_type)\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    pred = mobilenet.predict(img)[0]\n",
    "    print(f'{file}\\t\\t{np.argmax(pred)}\\t\\t{pred.max()}\\t\\t{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = GetPickles.get_image_value('../TestImages/AR.jpg', var.mobilenet_dimension, var.img_type)\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(img, mobilenet.predict, top_labels = 5, hide_color = 0, \n",
    "                                         num_samples = 1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only = False,\n",
    "                                           num_features = 10, hide_rest = False)\n",
    "plt.imshow(mark_boundaries(temp/2 + .5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions.get_prediction_bounding_box('../TestImages/AR.jpg', mobilenet, var.mobilenet_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
