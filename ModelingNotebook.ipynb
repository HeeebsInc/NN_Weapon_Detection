{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from PyFunctions import Functions as func\n",
    "from PyFunctions import var\n",
    "from PyFunctions import Viz\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model \n",
    "- The function below will compile and return a CNN model given the input dimensions \n",
    "- Categorical Crossentropy was used because the model is used to predict between three classes (0 = No Weapon, 1 = Handgun, 2 = Rifle) \n",
    "- Softmax output was used because this is a ternary classification problem \n",
    "- To ensure that training continued for more than 20 epochs\n",
    "- Dimension for thie model is optimized at (150, 150, 1) \n",
    "- All visualization functions can be found in the Viz.py file within the PyFunctions folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change edge parameter to false if you are using a non edges train_test_split\n",
    "edge = True\n",
    "x_train, x_test, y_train, y_test = func.get_samples('normal', edge = edge)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Running the cell below will show you what the input images look like.  \n",
    "- Creating these images used a gaussian filter that outline the edges within a photo \n",
    "- Using this approach allowed the algorithm to learn distinctive shapes between weapons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "cv2.imshow('test', x_train[1000])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model_normal(dim):\n",
    "    '''This function will create and compile a CNN given the input dimension'''\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model \n",
    "\n",
    "\n",
    "\n",
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim =dim)\n",
    "print(normal_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Augmentation\n",
    "- First started with augmentation of each image to determine if this would make the accuracy better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights/CNN-ModelCheckpointWeightsAugment.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                       horizontal_flip = True, shear_range = .15, \n",
    "                                 fill_mode = 'nearest', zoom_range = .15)\n",
    "augmentation.fit(x_train)\n",
    "normal_history = normal_model.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy With Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(normal_history, 'dark_background', path = 'figures/CNNModelAugment.png')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC and ROC Curves With Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('ModelWeights/CNN-ModelCheckpointWeightsAugment.h5') #load the best weights before overfitting\n",
    " \n",
    "\n",
    "\n",
    "Viz.plot_roc_auc(normal_model, x_test, y_test, 'dark_background', 'figures/ROCAUCAugment.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix With Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('ModelWeights/CNN-ModelCheckpointWeightsAugment.h5') #load the best weights before overfitting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_prob = [np.argmax(i) for i in normal_model.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "y_train_prob = [np.argmax(i) for i in normal_model.predict(x_train)]\n",
    "y_train_labels = [np.argmax(i) for i in y_train]\n",
    "train_cnf = confusion_matrix(y_train_labels, y_train_prob)\n",
    "\n",
    "Viz.plot_model_cm(test_cnf, train_cnf, classes = ['No Weapon', 'Handgun', 'Rifle'], theme = 'dark_background', \n",
    "                  path = 'figures/CMAugment.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Augmention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint('ModelWeights/CNN-ModelCheckpointWeightsNoAugment.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim =dim)\n",
    "\n",
    "\n",
    "normal_history = normal_model.fit(x_train, y_train, batch_size = batch_size,\n",
    "            epochs = epochs, \n",
    "     callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Accuracy without Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(normal_history, 'dark_background', path = 'figures/CNNModelNoAugment.png')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC and AUC without Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('ModelWeights/CNN-ModelCheckpointWeightsNoAugment.h5') #load the best weights before overfitting\n",
    " \n",
    "\n",
    "\n",
    "Viz.plot_roc_auc(normal_model, x_test, y_test, 'dark_background', 'figures/ROCAUCNoAugment.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Without Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('ModelWeights/CNN-ModelCheckpointWeightsNoAugment.h5') #load the best weights before overfitting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_prob = [np.argmax(i) for i in normal_model.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "y_train_prob = [np.argmax(i) for i in normal_model.predict(x_train)]\n",
    "y_train_labels = [np.argmax(i) for i in y_train]\n",
    "train_cnf = confusion_matrix(y_train_labels, y_train_prob)\n",
    "\n",
    "Viz.plot_model_cm(test_cnf, train_cnf, classes = ['No Weapon', 'Handgun', 'Rifle'], theme = 'dark_background', \n",
    "                  path = 'figures/CMNoAugment.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "- Comparing the confusion matrix of the augmented model with the non-augmented model, we can see that the non-augmented model performs much better at detection the presence of the weapon.  \n",
    "- This difference can be due to the fact that the images that are being fed into the algorithm are already processes in a way that only makes it more confusing when applying augmentation as well\n",
    "- The model weights `CNN-ModelCheckpointWeightsNoAugment.h5` correspond to the final model used throughout the visualizations found in `OpenCVTesting` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
