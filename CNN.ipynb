{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import Functions as func\n",
    "import GetPickles\n",
    "import var\n",
    "import Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model_normal(dim):\n",
    "    \n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .5 \n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    dil_rate = 2\n",
    "    \n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (2,2)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (2,2)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(32, activation='relu'))\n",
    "\n",
    "\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = GetPickles.get_samples('normal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6036, 96, 96, 3) (671, 96, 96, 3)\n",
      "(6036, 3) (671, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "189/189 [==============================] - 51s 269ms/step - loss: 5.0119 - acc: 0.5872 - val_loss: 2.2188 - val_acc: 0.6930\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.21877, saving model to ../models/CNN-ModelCheckpointWeights.h5\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 25s 134ms/step - loss: 1.7892 - acc: 0.6896 - val_loss: 1.4504 - val_acc: 0.7019\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.21877 to 1.45040, saving model to ../models/CNN-ModelCheckpointWeights.h5\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 25s 133ms/step - loss: 1.3942 - acc: 0.6904 - val_loss: 1.3270 - val_acc: 0.6841\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.45040 to 1.32701, saving model to ../models/CNN-ModelCheckpointWeights.h5\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 25s 133ms/step - loss: 1.2452 - acc: 0.7103 - val_loss: 1.1621 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.32701 to 1.16214, saving model to ../models/CNN-ModelCheckpointWeights.h5\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 25s 132ms/step - loss: 1.1362 - acc: 0.7270 - val_loss: 1.1218 - val_acc: 0.7154\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16214 to 1.12182, saving model to ../models/CNN-ModelCheckpointWeights.h5\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 25s 133ms/step - loss: 1.1485 - acc: 0.7102 - val_loss: 1.2494 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.12182\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 25s 133ms/step - loss: 1.1757 - acc: 0.7172 - val_loss: 1.3042 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.12182\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 25s 133ms/step - loss: 1.1094 - acc: 0.7173 - val_loss: 1.2124 - val_acc: 0.6826\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.12182\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 25s 133ms/step - loss: 0.9969 - acc: 0.7376 - val_loss: 1.0969 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.12182 to 1.09691, saving model to ../models/CNN-ModelCheckpointWeights.h5\n",
      "Epoch 10/100\n",
      "116/189 [=================>............] - ETA: 9s - loss: 0.9764 - acc: 0.7439"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "augment = True \n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=14)\n",
    "model_checkpoint = ModelCheckpoint('../models/CNN-ModelCheckpointWeights.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 3, mode = 'min')\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "if var.img_type == 'grey': \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 1)\n",
    "else: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim =dim)\n",
    "\n",
    "if augment: \n",
    "    augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .1, height_shift_range = .1, \n",
    "                                                           horizontal_flip = True, fill_mode = 'nearest')\n",
    "    augmentation.fit(x_train)\n",
    "    normal_history = normal_model.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "                epochs = epochs, \n",
    "         callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n",
    "else: \n",
    "    \n",
    "    normal_history = normal_model.fit(x_train, y_train, batch_size = batch_size,\n",
    "                epochs = epochs, \n",
    "         callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(normal_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(normal_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC and ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights.h5') #load the best weights before overfitting\n",
    " \n",
    "\n",
    "Viz.plot_roc_auc(normal_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights.h5') #load the best weights before overfitting\n",
    "\n",
    "y_test_prob = normal_model.predict(x_test).ravel()\n",
    "\n",
    "y_train_prob = normal_model.predict(x_train).ravel()\n",
    "\n",
    "Viz.plot_model_cm(y_train = y_train, y_test = y_test, y_train_prob = y_train_prob,\n",
    "                      y_test_prob = y_test_prob,classes = ['No Weapon', 'Weapon'], thresholds = [.2, .5,.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Google Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights.h5')\n",
    "img = func.get_image_value('../test3.jpg', var.norm_dimension, var.img_type)\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(img, normal_model.predict, top_labels = 5, hide_color = 0, \n",
    "                                         num_samples = 1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only = False,\n",
    "                                           num_features = 10, hide_rest = False)\n",
    "plt.imshow(mark_boundaries(temp/2 + .5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights.h5')\n",
    "\n",
    "img = cv2.imread('../test3.jpg')\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(img)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rects = ss.process() \n",
    "\n",
    "windows = []\n",
    "locations = []\n",
    "for x, y, w,h in rects: \n",
    "    startx = x \n",
    "    starty = y \n",
    "    endx = x+w \n",
    "    endy = y+h \n",
    "    roi = img[starty:endy, startx:endx]\n",
    "    roi = cv2.resize(roi, dsize =var.norm_dimension, interpolation = cv2.INTER_CUBIC)\n",
    "    windows.append(roi)\n",
    "    locations.append((startx, starty, endx, endy))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.array(windows)\n",
    "\n",
    "predictions = normal_model.predict(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in predictions:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = img.copy()\n",
    "new_loc = [] \n",
    "new_prob = [] \n",
    "for idx, i in enumerate(predictions): \n",
    "    if i != 1: \n",
    "        continue\n",
    "    startx, starty, endx, endy = locations[idx]\n",
    "    cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,255,0),2)\n",
    "    text = f'Weapon: {i*100}'\n",
    "    cv2.putText(clone, text, (startx, y), cv2.FONT_HERSHEY_SIMPLEX, .45, (0,255,0),2)\n",
    "    new_loc.append(locations[idx])\n",
    "    new_prob.append(i[0])\n",
    "    \n",
    "cv2.imshow('test', clone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxid = func.non_max_suppression(np.array(new_loc), np.array(new_prob))[0]\n",
    "boxid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = img.copy()\n",
    "  \n",
    "startx, starty, endx, endy = new_loc[boxid]\n",
    "cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,255,0),2)\n",
    "text = f'Weapon: {i*100}'\n",
    "cv2.putText(clone, text, (startx, y), cv2.FONT_HERSHEY_SIMPLEX, .45, (0,255,0),2)\n",
    "cv2.imshow('test', clone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = img.copy()\n",
    "roi = clone[starty:endy, startx:endx]\n",
    "roi = cv2.resize(roi, dsize =var.dimension, interpolation = cv2.INTER_CUBIC)\n",
    "# cv2.imshow('test', roi)\n",
    "# cv2.waitKey(0)\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(roi, normal_model.predict, top_labels = 5, hide_color = 0, \n",
    "                                         num_samples = 1000)\n",
    "\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only = False,\n",
    "                                           num_features = 10, hide_rest = False)\n",
    "plt.imshow(mark_boundaries(temp/2 + .5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
