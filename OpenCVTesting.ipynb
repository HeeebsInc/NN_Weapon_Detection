{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from PyFunctions import Functions as func\n",
    "from PyFunctions import var\n",
    "from PyFunctions import ModelFunc as modelfunc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "- Within the folder tests, add whatever image you would like that contains a gun and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_prediction_bounding_box(path, model, dim, edge = False):\n",
    "    '''This function will create a bounding box over what it believes is a weapon given the image path, dimensions, and model used to detect the weapon.  Dimensions can be found within the Var.py file.  This function is still being used as I need to apply non-max suppresion to create only one bounding box'''\n",
    "    \n",
    "    img = func.get_image_value(path, dim, edge = edge)\n",
    "\n",
    "    if edge == True:\n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
    "    else: \n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    \n",
    "    pred = model.predict(img)[0]\n",
    "    \n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    \n",
    "    print(f'{path}\\t\\t{cat_index}||{cat}\\t\\t{pred.max()}\\t\\t{pred}')\n",
    "    return None \n",
    "    img = cv2.imread(path)\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "#     ss.switchToSelectiveSearchQuality()\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "\n",
    "    rects = ss.process() \n",
    "\n",
    "    windows = []\n",
    "    locations = []\n",
    "    print(f'Creating Bounding Boxes for {path}')\n",
    "    for x, y, w,h in rects[:1500]: \n",
    "        startx = x \n",
    "        starty = y \n",
    "        endx = x+w \n",
    "        endy = y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        if edge == True:\n",
    "            roi = get_edged(roi, dim = dim)\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    if edge == True:\n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 1)\n",
    "    else: \n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    windows = np.array(windows)\n",
    "    locations = np.array(locations)\n",
    "    predictions = model.predict(windows)\n",
    "    \n",
    "#     pick = func.non_max_suppression(locations, probs = None)\n",
    "#     clone = img.copy() \n",
    "#     clone2 = img.copy()\n",
    "#     for idx in pick: \n",
    "#         startx, startx, endx, endy = locations[idx]\n",
    "#         cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "        \n",
    "    \n",
    "#GOES HERE \n",
    "    cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n",
      "C:\\Users\\Heeeb\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests/Photos/AR.jpg\t\t2||Rifle\t\t0.9998019337654114\t\t[1.4862098e-04 4.9498449e-05 9.9980193e-01]\n",
      "Tests/Photos/AR2.jpg\t\t2||Rifle\t\t0.951600968837738\t\t[0.00314434 0.04525468 0.95160097]\n",
      "Tests/Photos/NoWeap.jpg\t\t0||No Weapon\t\t0.9318897724151611\t\t[0.9318898  0.04441858 0.02369164]\n",
      "Tests/Photos/Pistol.jpg\t\t1||Handgun\t\t0.9985342025756836\t\t[1.7059132e-04 9.9853420e-01 1.2952359e-03]\n",
      "Tests/Photos/Pistol2.jpg\t\t1||Handgun\t\t0.9953504204750061\t\t[0.001173   0.9953504  0.00347659]\n",
      "Tests/Photos/Pistol3.jpg\t\t1||Handgun\t\t0.981045126914978\t\t[0.00139262 0.9810451  0.01756224]\n"
     ]
    }
   ],
   "source": [
    "#Mobilenet MODEL\n",
    "edge = False\n",
    "dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 3)\n",
    "    \n",
    "mobilenet = modelfunc.get_mobilenet(dim)\n",
    "mobilenet.load_weights('ModelWeights/Mobilenet.h5') \n",
    "\n",
    "test_folder = 'Tests/Photos'\n",
    "\n",
    "for i in os.listdir(test_folder):\n",
    "    if i == 'ipynb_checkpoints': \n",
    "        continue\n",
    "    img_path = f'{test_folder}/{i}'\n",
    "    predictions = get_img_prediction_bounding_box(img_path, mobilenet, dim = var.mobilenet_dimension, edge = edge)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests/Photos/AR.jpg\t\t2||Rifle\t\t0.9925839900970459\t\t[2.191613e-05 7.394147e-03 9.925840e-01]\n",
      "Tests/Photos/AR2.jpg\t\t2||Rifle\t\t0.7940834164619446\t\t[0.00379495 0.20212175 0.7940834 ]\n",
      "Tests/Photos/NoWeap.jpg\t\t2||Rifle\t\t0.5544159412384033\t\t[0.3175555  0.12802847 0.55441594]\n",
      "Tests/Photos/Pistol.jpg\t\t1||Handgun\t\t0.872041642665863\t\t[5.3711003e-05 8.7204164e-01 1.2790467e-01]\n",
      "Tests/Photos/Pistol2.jpg\t\t1||Handgun\t\t0.6976065039634705\t\t[3.2739833e-04 6.9760650e-01 3.0206609e-01]\n",
      "Tests/Photos/Pistol3.jpg\t\t2||Rifle\t\t0.8115520477294922\t\t[0.00087078 0.18757713 0.81155205]\n"
     ]
    }
   ],
   "source": [
    "#NORMAL MODEL\n",
    "edge = False\n",
    "dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = modelfunc.get_conv_model(dim)\n",
    "normal_model.load_weights('ModelWeights/V2_NoEdge_NoAugmentation.h5') #path to the model weights\n",
    "\n",
    "test_folder = 'Tests/Photos'\n",
    "\n",
    "for i in os.listdir(test_folder):\n",
    "    if i == 'ipynb_checkpoints': \n",
    "        continue\n",
    "    img_path = f'{test_folder}/{i}'\n",
    "    predictions = get_img_prediction_bounding_box(img_path, normal_model, dim = var.norm_dimension, edge = edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, probs, overlapThresh=0.5):\n",
    "    '''This function was taken and modified from PyImage search = a blog that teaches deep learning techniques using images. \n",
    "    This function will extract all the bounding boxes with a certain threshold of overlap'''\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes are integers, convert them to floats -- this\n",
    "    # is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    # compute the area of the bounding boxes and grab the indexes to sort\n",
    "    # (in the case that no probabilities are provided, simply sort on the\n",
    "    # bottom-left y-coordinate)\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = y2\n",
    "\n",
    "    # if probabilities are provided, sort on them instead\n",
    "    if probs is not None:\n",
    "        idxs = probs\n",
    "\n",
    "    # sort the indexes\n",
    "    idxs = np.argsort(idxs)\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value\n",
    "        # to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding\n",
    "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
    "        # box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have overlap greater\n",
    "        # than the provided overlap threshold\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return the indexes of only the bounding boxes to keep\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video \n",
    "- within the folder Tests, add whatever video (.mp4) that contains a gun and run the cell below\n",
    "- **Note**: Stick t video shorter than a minute or this process will take a very long time depending on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge= True \n",
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0],var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('ModelWeights/CNN-ModelCheckpointWeightsNoAugment.h5')\n",
    "\n",
    "images = get_vid_frames('../Tests/Videos/Pistol2.mp4', normal_model, var.norm_dimension, edge = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(images, desc= 'Getting Base Prediction and Extracting Sliding Window... Sit Back, This Will Take A While')\n",
    "windows_prob = [window_prob_func(img, normal_model, var.norm_dimension, edge = edge) for img in pbar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_dim = (224,224)\n",
    "vid_dim = var.norm_dimension\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Tests/VideoOutput/BoundingBox.mp4',fourcc, 10, vid_dim) #change the filename to whatever you would like\n",
    "\n",
    "\n",
    "for prob, img in zip(windows_prob, images): \n",
    "    clone = img.copy()\n",
    "    if prob == None:\n",
    "        out.write(clone)\n",
    "    else:\n",
    "        (p, (startx, starty, endx, endy)) = prob\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "        out.write(clone)\n",
    "        \n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
