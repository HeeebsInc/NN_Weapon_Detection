{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import Functions as func\n",
    "import var\n",
    "import Viz\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### best is model weights 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model_normal(activation = 'relu', dropout = .25, kernal_reg = regularizers.l1(), kern_init = 'he_uniform', \n",
    "                         pad = 'same', opt = 'adam'):\n",
    "    \n",
    "    inp_shape = (96,96,3)\n",
    "   \n",
    "#     kernal_reg = regularizers.l1(kern_lr)\n",
    "    dil_rate = 2\n",
    "#     optimizer = Adam(lr = opt_lr)\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=activation, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = kern_init,  padding = pad, name = 'Input_Layer'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation=activation, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = kern_init,padding = pad))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = kern_init, padding = pad))\n",
    "    model.add(Conv2D(128, (3, 3), activation=activation, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = kern_init, padding = pad))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dense(32, activation=activation))\n",
    "\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6512, 96, 96, 3) (724, 96, 96, 3)\n",
      "(6512, 3) (724, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = func.get_samples('normal')\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# param_grid = {\n",
    "#     'activation': 'relu tanh sigmoid hard_sigmoid linear'.split(), \n",
    "#     'momentum': [0.0, .2, .4, .6, .8, .9], \n",
    "#     'learn_rate': [.001, .01, .1, .2, .3], \n",
    "#     'dropout_rate': [0.0, .1, .2, .3, .4, .5, .6, .7, .8, .9], \n",
    "#     'weight_contraint': [1, 2, 3, 4, 5], \n",
    "#     'neurons': [1,5,10,15,20,25,30],\n",
    "#     'init': 'uniform lecun_uniform normal zero glorot_normal glorot_uniform he_normal he_uniform'.split(), \n",
    "#     'optimizer': 'SGD RMSprop Adagrad Adadelta Adam Adamax Nadam'.split(), \n",
    "#     'epochs': [25], \n",
    "#     'batch_size': [16, 32, 64],     \n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'activation': 'relu'.split(), \n",
    "    'dropout': [0.0, .3, .6, .9], \n",
    "    'epochs': [25], \n",
    "    'batch_size': [16, 32, 64],  \n",
    "    'opt': ['Adam', 'Nadam'], \n",
    "    'kernal_reg': [regularizers.l1(.001), regularizers.l2(.001)], \n",
    "    'pad': ['same'], \n",
    "    'kern_init': 'he_uniform'.split()\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "normal_model = KerasClassifier(build_fn = get_conv_model_normal, batch_size = 16, epochs = 20)\n",
    "\n",
    "grid = GridSearchCV(estimator = normal_model, param_grid = param_grid, verbose = 2, n_jobs = 12, cv = 2)\n",
    "\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid, open('../Pickles/GridSearchCNN.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "augment = True \n",
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=14)\n",
    "model_checkpoint = ModelCheckpoint('../models/CNN-ModelCheckpointWeights3.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "lr_plat = ReduceLROnPlateau(patience = 3, mode = 'min')\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "if var.img_type == 'grey': \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 1)\n",
    "else: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim =dim)\n",
    "\n",
    "if augment: \n",
    "    augmentation =ImageDataGenerator(rotation_range = 20, width_shift_range = .2, height_shift_range = .2, \n",
    "                                                           horizontal_flip = True, shear_range = .15, \n",
    "                                     fill_mode = 'nearest', zoom_range = .15)\n",
    "    augmentation.fit(x_train)\n",
    "    normal_history = normal_model.fit_generator(augmentation.flow(x_train, y_train, batch_size = batch_size),\n",
    "                epochs = epochs, \n",
    "         callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n",
    "else: \n",
    "    \n",
    "    normal_history = normal_model.fit(x_train, y_train, batch_size = batch_size,\n",
    "                epochs = epochs, \n",
    "         callbacks = [early_stopping, model_checkpoint, lr_plat], validation_data = (x_test, y_test), verbose= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(normal_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Viz.plot_loss_accuracy(normal_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC and ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights3.h5') #load the best weights before overfitting\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "Viz.plot_roc_auc(normal_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights3.h5') #load the best weights before overfitting\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_prob = [np.argmax(i) for i in normal_model.predict(x_test)]\n",
    "y_test_labels = [np.argmax(\n",
    "    i) for i in y_test]\n",
    "test_cnf = confusion_matrix(y_test_labels, y_test_prob)\n",
    "\n",
    "y_train_prob = [np.argmax(i) for i in normal_model.predict(x_train)]\n",
    "y_train_labels = [np.argmax(i) for i in y_train]\n",
    "train_cnf = confusion_matrix(y_train_labels, y_train_prob)\n",
    "\n",
    "Viz.plot_model_cm(test_cnf, train_cnf, classes = ['No Weapon', 'Handgun', 'Rifle'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on Google Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../Tests/Photos'\n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights3.h5')\n",
    "\n",
    "for file in os.listdir(base_path): \n",
    "    if file == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    full_path = f'{base_path}/{file}'\n",
    "    img = func.get_image_value(full_path, var.norm_dimension, var.img_type)\n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "    pred = normal_model.predict(img)[0]\n",
    "    print(f'{file}\\t\\t{np.argmax(pred)}\\t\\t{pred.max()}\\t\\t{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3\n",
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "\n",
    "img = func.get_image_value('../Tests/Photos/AR.jpg', var.norm_dimension, var.img_type)\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(img, normal_model.predict, top_labels = 5, hide_color = 0, \n",
    "                                         num_samples = 1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only = False,\n",
    "                                           num_features = 10, hide_rest = False)\n",
    "plt.imshow(mark_boundaries(temp/2 + .5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Functions.get_img_prediction_bounding_box('../Tests/Photos/Pistol3.jpg', normal_model, var.norm_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if var.img_type == 'grey': \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "        \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights2.h5')\n",
    "\n",
    "img = cv2.imread('../TestImages/AR.jpg')\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "ss.setBaseImage(img)\n",
    "ss.switchToSelectiveSearchFast()\n",
    "rects = ss.process() \n",
    "\n",
    "windows = []\n",
    "locations = []\n",
    "for x, y, w,h in rects: \n",
    "    startx = x \n",
    "    starty = y \n",
    "    endx = x+w \n",
    "    endy = y+h \n",
    "    roi = img[starty:endy, startx:endx]\n",
    "    roi = cv2.resize(roi, dsize =var.norm_dimension, interpolation = cv2.INTER_CUBIC)\n",
    "    windows.append(roi)\n",
    "    locations.append((startx, starty, endx, endy))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = np.array(windows[:2000])\n",
    "\n",
    "predictions = normal_model.predict(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in predictions:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = img.copy()\n",
    "new_loc = [] \n",
    "new_prob = [] \n",
    "no_gun = predictions[:, 0].sum()\n",
    "handgun = predictions[:,1].sum()\n",
    "rifle = predictions[:,2].sum()\n",
    "sum_array = np.array([no_gun, handgun, rifle])\n",
    "index_unit = np.argmax(sum_array)\n",
    "cat_types = ['No Gun', 'Handgun', 'Rifle']\n",
    "print(index_unit)\n",
    "print(no_gun, handgun, rifle)\n",
    "new_locations = []\n",
    "for idx, i in enumerate(predictions):\n",
    "    category = i[index_unit]\n",
    "    if category > .5:\n",
    "        startx, starty, endx, endy = locations[idx]\n",
    "        new_locations.append([startx, starty, endx, endy])\n",
    "        new_loc.append(locations[idx])\n",
    "        new_prob.append(category)\n",
    "\n",
    "new_locations = np.array(new_locations)\n",
    "\n",
    "startx = int(new_locations[:,0].mean())\n",
    "starty =int( new_locations[:,1].mean())\n",
    "endx = int(new_locations[:,2].mean())\n",
    "endy = int(new_locations[:,3].mean())\n",
    "\n",
    "\n",
    "# startx = int(np.median (new_locations[:,0]))\n",
    "# starty =int( np.median (new_locations[:,1]))\n",
    "# endx = int(np.median (new_locations[:,2]))\n",
    "# endy = int(np.median(new_locations[:,3]))\n",
    "\n",
    "prob_avg = np.array(new_prob).mean()\n",
    "\n",
    "\n",
    "cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,255,0),2)\n",
    "\n",
    "text = f'{cat_types[index_unit]}: {int(prob_avg*100)}'\n",
    "cv2.putText(clone, text, (startx, starty), cv2.FONT_HERSHEY_SIMPLEX, .45, (0,255,0),2)\n",
    "   \n",
    "    \n",
    "cv2.imshow('test', clone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = img.copy()\n",
    "  \n",
    "startx, starty, endx, endy = new_loc[boxid]\n",
    "cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,255,0),2)\n",
    "text = f'Weapon: {i*100}'\n",
    "cv2.putText(clone, text, (startx, y), cv2.FONT_HERSHEY_SIMPLEX, .45, (0,255,0),2)\n",
    "cv2.imshow('test', clone)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone = img.copy()\n",
    "roi = clone[starty:endy, startx:endx]\n",
    "roi = cv2.resize(roi, dsize =var.dimension, interpolation = cv2.INTER_CUBIC)\n",
    "# cv2.imshow('test', roi)\n",
    "# cv2.waitKey(0)\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(roi, normal_model.predict, top_labels = 5, hide_color = 0, \n",
    "                                         num_samples = 1000)\n",
    "\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only = False,\n",
    "                                           num_features = 10, hide_rest = False)\n",
    "plt.imshow(mark_boundaries(temp/2 + .5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
