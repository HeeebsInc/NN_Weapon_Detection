{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from PyFunctions import Functions as func\n",
    "from PyFunctions import var\n",
    "from PyFunctions import ModelFunc as modelfunc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video \n",
    "- within the folder Tests, add whatever video (.mp4) that contains a gun and run the cell below\n",
    "- **Note**: Stick t video shorter than a minute or this process will take a very long time depending on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_frames(path, dim, edge = False): \n",
    "    '''This function will take a path to an mp4 file and return a list containing each frame of the video.  This function is used for creating bounding boxes within a video'''\n",
    "    from tqdm import tqdm\n",
    "    vid = cv2.VideoCapture(path)\n",
    "    total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total = total_frames, desc = f'Splitting Video Into {total_frames} Frames')\n",
    "    images = [] \n",
    "    sucess =1 \n",
    "    while True: \n",
    "        try:\n",
    "            success, img = vid.read() \n",
    "            img = cv2.resize(img, dim, interpolation = cv2.INTER_CUBIC)\n",
    "            images.append(img)\n",
    "            pbar.update(1)\n",
    "        except: \n",
    "            break\n",
    "        \n",
    "\n",
    "    pbar.close()\n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def window_prob_func(img, model, dim, edge):\n",
    "    '''Given an image, this function will extract the segmented bounding boxes and return the ones with the rest ROI (using non_max_suppresion.  If there is no overlap, it will return None)'''\n",
    "    if edge == True:\n",
    "        img_copy = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
    "    else: \n",
    "        img_copy = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "        \n",
    "    pred = model.predict(img_copy)[0]\n",
    "        \n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    \n",
    "#     print(f'{path}\\t\\tPrediction: {cat}\\t{round(pred.max()*100)}% Confident')\n",
    "      \n",
    "    \n",
    "    if cat_index != 0:\n",
    "        ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "        ss.setBaseImage(img)\n",
    "        ss.switchToSelectiveSearchQuality()\n",
    "    #     ss.switchToSelectiveSearchFast()\n",
    "\n",
    "        rects = ss.process() \n",
    "\n",
    "        windows = []\n",
    "        locations = []\n",
    "        for x, y, w,h in rects: \n",
    "            startx = x \n",
    "            starty = y \n",
    "            endx = x+w \n",
    "            endy = y+h \n",
    "            roi = img[starty:endy, startx:endx]\n",
    "            if edge == True:\n",
    "                roi = get_edged(roi, dim = dim)\n",
    "            roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "            windows.append(roi)\n",
    "            locations.append((startx, starty, endx, endy))\n",
    "\n",
    "        windows = np.array(windows)\n",
    "        if edge == True:\n",
    "            windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 1)\n",
    "        else: \n",
    "            windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "        windows = np.array(windows)\n",
    "        locations = np.array(locations)\n",
    "        predictions = model.predict(windows)\n",
    "\n",
    "        cat_predictions = predictions[:,cat_index]\n",
    "        pred_max_idx = np.argmax(cat_predictions)\n",
    "        pred_max = cat_predictions[pred_max_idx]\n",
    "\n",
    "        pred_max_window = locations[pred_max_idx]\n",
    "        startx, starty, endx, endy = pred_max_window\n",
    "        \n",
    "        return (pred_max, (startx, starty, endx, endy))\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Video Into 720 Frames: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 720/720 [00:02<00:00, 303.42it/s]\n"
     ]
    }
   ],
   "source": [
    "edge = False\n",
    "images = get_vid_frames('../Tests/Videos/Pistol2.mp4', var.mobilenet_dimension, edge = edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n",
      "C:\\Users\\Heeeb\\Anaconda3\\lib\\site-packages\\keras_applications\\mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "Getting Base Prediction and Extracting Sliding Window... Sit Back, This Will Take A While: 100%|████████████████████████████████████████████████████████| 720/720 [07:41<00:00,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dim = (var.mobilenet_dimension[0], var.mobilenet_dimension[1], 3)\n",
    "    \n",
    "mobilenet = modelfunc.get_mobilenet(dim)\n",
    "mobilenet.load_weights('ModelWeights/Mobilenet.h5')\n",
    "\n",
    "pbar = tqdm(images, desc= 'Getting Base Prediction and Extracting Sliding Window... Sit Back, This Will Take A While')\n",
    "windows_prob = [window_prob_func(img, mobilenet, var.mobilenet_dimension, edge = edge) for img in pbar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 153 199 224\n",
      "0 80 43 136\n",
      "2 90 51 139\n",
      "13 0 98 135\n",
      "28 0 98 124\n",
      "104 0 224 224\n",
      "70 168 108 224\n",
      "111 175 161 224\n",
      "45 0 200 224\n",
      "143 126 178 150\n",
      "158 123 193 148\n",
      "157 48 189 224\n",
      "156 47 189 194\n",
      "159 46 190 194\n",
      "157 48 189 224\n",
      "62 107 117 164\n",
      "58 104 115 164\n",
      "67 105 116 165\n",
      "57 104 113 164\n",
      "114 32 156 69\n",
      "48 108 63 145\n",
      "113 32 149 68\n",
      "50 108 105 166\n",
      "72 32 157 142\n",
      "154 0 224 224\n",
      "35 33 137 123\n",
      "86 17 158 123\n",
      "87 16 151 123\n",
      "35 17 158 129\n",
      "35 17 158 126\n",
      "35 134 139 187\n",
      "35 72 111 123\n",
      "35 72 111 123\n",
      "151 0 224 224\n",
      "69 0 170 122\n",
      "67 103 143 187\n",
      "78 135 140 186\n",
      "41 0 224 125\n",
      "157 8 224 224\n",
      "66 0 173 143\n",
      "142 7 148 80\n",
      "177 108 224 127\n",
      "69 121 117 146\n",
      "61 47 140 206\n",
      "139 11 176 36\n",
      "178 108 213 127\n",
      "118 10 178 44\n",
      "177 108 188 126\n",
      "48 13 151 148\n"
     ]
    }
   ],
   "source": [
    "vid_dim = (224,224)\n",
    "vid_dim = var.mobilenet_dimension\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Tests/VideoOutput/MobilenetBoundingBox.mp4',fourcc, 10, vid_dim) #change the filename to whatever you would like\n",
    "\n",
    "\n",
    "for prob, img in zip(windows_prob, images): \n",
    "    clone = img.copy()\n",
    "    if prob == None:\n",
    "        out.write(clone)\n",
    "    else:\n",
    "        (startx, starty, endx, endy) = prob[1]\n",
    "        print(startx, starty, endx, endy)\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "        out.write(clone)\n",
    "        \n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge= True \n",
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0],var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('ModelWeights/CNN-ModelCheckpointWeightsNoAugment.h5')\n",
    "\n",
    "images = get_vid_frames('../Tests/Videos/Pistol2.mp4', var.norm_dimension, edge = edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(images, desc= 'Getting Base Prediction and Extracting Sliding Window... Sit Back, This Will Take A While')\n",
    "windows_prob = [window_prob_func(img, normal_model, var.norm_dimension, edge = edge) for img in pbar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_dim = (224,224)\n",
    "vid_dim = var.norm_dimension\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('Tests/VideoOutput/BoundingBox.mp4',fourcc, 10, vid_dim) #change the filename to whatever you would like\n",
    "\n",
    "\n",
    "for prob, img in zip(windows_prob, images): \n",
    "    clone = img.copy()\n",
    "    if prob == None:\n",
    "        out.write(clone)\n",
    "    else:\n",
    "        (p, (startx, starty, endx, endy)) = prob\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "        out.write(clone)\n",
    "        \n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
