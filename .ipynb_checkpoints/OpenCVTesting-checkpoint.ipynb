{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, AveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "import Functions as func\n",
    "import var\n",
    "import Viz\n",
    "import cv2\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### best is model weights 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model_normal(dim):\n",
    "    inp_shape = dim\n",
    "    act = 'relu'\n",
    "    drop = .25\n",
    "    kernal_reg = regularizers.l1(.001)\n",
    "    optimizer = Adam(lr = .0001)\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3),activation=act, input_shape = inp_shape, \n",
    "                     kernel_regularizer = kernal_reg,\n",
    "                     kernel_initializer = 'he_uniform',  padding = 'same', name = 'Input_Layer'))\n",
    "#     model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),  strides = (3,3)))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "#     model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "    \n",
    "\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation=act, kernel_regularizer = kernal_reg, \n",
    "                     kernel_initializer = 'he_uniform',padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides = (3,3)))\n",
    "\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(drop))\n",
    "\n",
    "    model.add(Dense(3, activation='softmax', name = 'Output_Layer'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, probs, overlapThresh=0.5):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # if the bounding boxes are integers, convert them to floats -- this\n",
    "    # is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    # compute the area of the bounding boxes and grab the indexes to sort\n",
    "    # (in the case that no probabilities are provided, simply sort on the\n",
    "    # bottom-left y-coordinate)\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = y2\n",
    "\n",
    "    # if probabilities are provided, sort on them instead\n",
    "    if probs is not None:\n",
    "        idxs = probs\n",
    "\n",
    "    # sort the indexes\n",
    "    idxs = np.argsort(idxs)\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value\n",
    "        # to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding\n",
    "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
    "        # box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have overlap greater\n",
    "        # than the provided overlap threshold\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    # return the indexes of only the bounding boxes to keep\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, probs, overlapThresh=0.6):\n",
    "\n",
    "\n",
    "    # if the bounding boxes are integers, convert them to floats -- this\n",
    "    # is important since we'll be doing a bunch of divisions\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    "\n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    # compute the area of the bounding boxes and grab the indexes to sort\n",
    "    # (in the case that no probabilities are provided, simply sort on the\n",
    "    # bottom-left y-coordinate)\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = y2\n",
    "\n",
    "    # if probabilities are provided, sort on them instead\n",
    "\n",
    "    # sort the indexes\n",
    "    idxs = np.argsort(idxs)\n",
    "    # keep looping while some indexes still remain in the indexes list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list and add the index value\n",
    "        # to the list of picked indexes\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        # find the largest (x, y) coordinates for the start of the bounding\n",
    "        # box and the smallest (x, y) coordinates for the end of the bounding\n",
    "        # box\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        # compute the width and height of the bounding box\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        # compute the ratio of overlap\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        # delete all indexes from the index list that have overlap greater\n",
    "        # than the provided overlap threshold\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    \n",
    "    \n",
    "    prob_cat = [np.argmax(probs[i]) for i in pick]\n",
    "    print(prob_cat)\n",
    "    print(pick)\n",
    "    new_pick = [i for idx, i in enumerate(pick) if prob_cat[idx] in [1,2]]\n",
    "    print(new_pick)\n",
    "    # return the indexes of only the bounding boxes to keep\n",
    "    return pick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Tests/Photos/Pistol.jpg\t\t0||No Weapon\t\t0.9999030828475952\t\t[9.9990308e-01 9.5199466e-05 1.7230760e-06]\n",
      "(3497, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "#WITH MAX SUPPRESION\n",
    "\n",
    "\n",
    "#     clone = img.copy() \n",
    "#     clone2 = img.copy()\n",
    "#     for idx, pred in enumerate(predictions): \n",
    "#         if pred[1] == 1 or pred[2] == 1: \n",
    "#             startx, starty, endx, endy = locations[idx]\n",
    "#             cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "            \n",
    "#     no_sum = predictions[:,0].sum()\n",
    "#     pistol_sum = predictions[:,1].sum()\n",
    "#     rifle_sum = predictions[:,2].sum() \n",
    "#     sum_array = np.array([no_sum, pistol_sum, rifle_sum])\n",
    "#     print(sum_array)\n",
    "#     clone = img.copy()\n",
    "#     clone2 = img.copy()\n",
    "#     print(np.argmax(sum_array))\n",
    "#     cat_predictions = predictions[:,np.argmax(sum_array)]\n",
    "#     pred_max_idx = np.argmax(cat_predictions)\n",
    "#     pred_max = cat_predictions[pred_max_idx]\n",
    "    \n",
    "#     pred_max_window = locations[pred_max_idx]\n",
    "#     startx, starty, endx, endy = pred_max_window\n",
    "\n",
    "\n",
    "#     cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "#     cat = category_dict[np.argmax(sum_array)]\n",
    "#     text = f'{cat}'\n",
    "#     cv2.putText(clone, text, (startx, starty), cv2.FONT_HERSHEY_SIMPLEX, .45, (0,0,255),2)\n",
    "\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    return edged\n",
    "\n",
    "def get_edged(img, dim): \n",
    "    blurred = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    wide = cv2.Canny(blurred, 10,200)\n",
    "    tight = cv2.Canny(blurred, 225, 250)\n",
    "    auto = auto_canny(blurred)\n",
    "    wide = cv2.resize(wide, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    tight = cv2.resize(tight, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    auto = cv2.resize(auto, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    return wide\n",
    "\n",
    "\n",
    "def get_img_prediction_bounding_box(path, model, dim, edge = False):\n",
    "    img = func.get_image_value(path, dim, edge = edge)\n",
    "\n",
    "    if edge == True:\n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
    "    else: \n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    \n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    \n",
    "    print(f'{path}\\t\\t{cat_index}||{cat}\\t\\t{pred.max()}\\t\\t{pred}')\n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process() \n",
    "\n",
    "    windows = []\n",
    "    locations = []\n",
    "    for x, y, w,h in rects: \n",
    "        startx = x \n",
    "        starty = y \n",
    "        endx = x+w \n",
    "        endy = y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        if edge == True:\n",
    "            roi = get_edged(roi, dim = dim)\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    print(windows.shape)\n",
    "    if edge == True:\n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 1)\n",
    "    else: \n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    windows = np.array(windows)\n",
    "    locations = np.array(locations)\n",
    "    predictions = model.predict(windows)\n",
    "    \n",
    "#     pick = non_max_suppression(locations, probs = predictions)\n",
    "#     clone = img.copy() \n",
    "#     clone2 = img.copy()\n",
    "#     for idx in pick: \n",
    "#         startx, startx, endx, endy = locations[idx]\n",
    "#         cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "    clone = img.copy() \n",
    "    clone2 = img.copy()\n",
    "    for idx, i in enumerate(predictions): \n",
    "        if np.argmax(i) in [1,2]: \n",
    "            startx, starty, endx, endy = locations[idx]\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "        \n",
    "    \n",
    "#GOES HERE \n",
    "    cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "base_path = '../Tests/Photos'\n",
    "edge = True\n",
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights1.h5')\n",
    "\n",
    "img = get_img_prediction_bounding_box(f'{base_path}/Pistol.jpg', normal_model, var.norm_dimension, edge = edge)\n",
    "\n",
    "# for file in os.listdir(base_path):\n",
    "#     img = get_img_prediction_bounding_box(f'{base_path}/{file}', normal_model, var.norm_dimension, edge = edge)\n",
    "#     break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(img): \n",
    "    if np.argmax(i) in [1,2]: \n",
    "        print(idx, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting Video Into 720 Frames: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 720/720 [00:02<00:00, 308.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    return edged\n",
    "\n",
    "def get_edged(img, dim): \n",
    "    blurred = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    wide = cv2.Canny(blurred, 10,200)\n",
    "    tight = cv2.Canny(blurred, 225, 250)\n",
    "    auto = auto_canny(blurred)\n",
    "    wide = cv2.resize(wide, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    tight = cv2.resize(tight, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    auto = cv2.resize(auto, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    return wide\n",
    "\n",
    "def get_vid_prediction_bounding_box(path, model, dim, edge = False): \n",
    "    vid = cv2.VideoCapture(path)\n",
    "    total_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total = total_frames, desc = f'Splitting Video Into {total_frames} Frames')\n",
    "    images = [] \n",
    "    sucess =1 \n",
    "    while True: \n",
    "        try:\n",
    "            success, img = vid.read() \n",
    "            img = cv2.resize(img, dim, interpolation = cv2.INTER_CUBIC)\n",
    "            images.append(img)\n",
    "            pbar.update(1)\n",
    "        except: \n",
    "            break\n",
    "        \n",
    "\n",
    "    pbar.close()\n",
    "    images = np.array(images)\n",
    "    \n",
    "    return images\n",
    "   \n",
    "edge= True \n",
    "if edge == True: \n",
    "    dim = (var.norm_dimension[0],var.norm_dimension[1], 1)\n",
    "else: \n",
    "    dim = (var.norm_dimension[0], var.norm_dimension[1], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights1.h5')\n",
    "\n",
    "images = get_vid_prediction_bounding_box('../Tests/Videos/Pistol2.mp4', normal_model, var.norm_dimension, edge = True)\n",
    "# predictions = normal_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting Base Prediction and Extracting Sliding Window... Sit Back, This Will Take A While: 100%|████████████████████████████████████████████████████████| 720/720 [05:13<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "def window_prob_func(img, model, dim, edge):\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process() \n",
    "\n",
    "    windows = []\n",
    "    locations = []\n",
    "    for x, y, w,h in rects: \n",
    "        startx = x \n",
    "        starty = y \n",
    "        endx = x+w \n",
    "        endy = y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        if edge == True:\n",
    "            roi = get_edged(roi, dim = dim)\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    if edge == True:\n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 1)\n",
    "    else: \n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    predictions = model.predict(windows)\n",
    "    locations = np.array(locations)\n",
    "#     for idx, pred in enumerate(predictions): \n",
    "#         if pred[1] == 1 or pred[2] == 1: \n",
    "#             startx, starty, endx, endy = locations[idx]\n",
    "#             return (1, (startx, starty, endx, endy))\n",
    "    pick = non_max_suppression(locations, probs = None)\n",
    "    for idx in pick: \n",
    "        prob = predictions[idx]\n",
    "        if np.argmax(prob) == 0: \n",
    "            continue\n",
    "        startx, startx, endx, endy = locations[idx]\n",
    "        return (prob, (startx, starty, endx, endy))\n",
    "\n",
    "        \n",
    "    return None\n",
    "\n",
    "pbar = tqdm(images, desc= 'Getting Base Prediction and Extracting Sliding Window... Sit Back, This Will Take A While')\n",
    "windows_prob = [window_prob_func(img, normal_model, var.norm_dimension, edge = edge) for img in pbar]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in windows_prob: \n",
    "    print([np.argmax(y) for y in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = pickle.load(open('../Pickles/WindowsPropPistol_CNNTester.p', 'rb'))\n",
    "for i in last: \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(windows_prob, open('../Pickles/WindowsPropPistol_CNNTester1.p', 'wb'))\n",
    "\n",
    "vid_dim = (224,224)\n",
    "vid_dim = var.norm_dimension\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('../Tests/VideoTests/TestCNNTESTER1.mp4',fourcc, 10, vid_dim)\n",
    "\n",
    "\n",
    "for prob, img in zip(windows_prob, images): \n",
    "    clone = img.copy()\n",
    "    if prob == None:\n",
    "#         clone = cv2.resize(clone, dsize =vid_dim, interpolation = cv2.INTER_CUBIC)      \n",
    "        out.write(clone)\n",
    "    else:\n",
    "        (p, (startx, starty, endx, endy)) = prob\n",
    "        cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "        out.write(clone)\n",
    "        \n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITHOUT MAX SUPPRESION\n",
    "def auto_canny(image, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "    return edged\n",
    "\n",
    "def get_edged(img, dim): \n",
    "    blurred = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    wide = cv2.Canny(blurred, 10,200)\n",
    "    tight = cv2.Canny(blurred, 225, 250)\n",
    "    auto = auto_canny(blurred)\n",
    "    wide = cv2.resize(wide, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    tight = cv2.resize(tight, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    auto = cv2.resize(auto, dim, interpolation = cv2.INTER_CUBIC)\n",
    "    return wide\n",
    "\n",
    "\n",
    "\n",
    "def get_img_prediction_bounding_box(path, model, dim, edge = False):\n",
    "    img = func.get_image_value(path, dim, edge = edge)\n",
    "\n",
    "    if edge == True:\n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
    "    else: \n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = model.predict(img)[0]\n",
    "    \n",
    "    category_dict = {0: 'No Weapon', 1: 'Handgun', 2: 'Rifle'}\n",
    "    cat_index = np.argmax(pred)\n",
    "    cat = category_dict[cat_index]\n",
    "    \n",
    "    print(f'{path}\\t\\t{cat_index}||{cat}\\t\\t{pred.max()}\\t\\t{pred}')\n",
    "    \n",
    "    \n",
    "    img = cv2.imread(path)\n",
    "    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "    ss.setBaseImage(img)\n",
    "    ss.switchToSelectiveSearchFast()\n",
    "    rects = ss.process() \n",
    "\n",
    "    windows = []\n",
    "    locations = []\n",
    "    for x, y, w,h in rects: \n",
    "        startx = x \n",
    "        starty = y \n",
    "        endx = x+w \n",
    "        endy = y+h \n",
    "        roi = img[starty:endy, startx:endx]\n",
    "        if edge == True:\n",
    "            roi = get_edged(roi, dim = dim)\n",
    "        roi = cv2.resize(roi, dsize =dim, interpolation = cv2.INTER_CUBIC)\n",
    "        windows.append(roi)\n",
    "        locations.append((startx, starty, endx, endy))\n",
    "\n",
    "    windows = np.array(windows)\n",
    "    print(windows.shape)\n",
    "    if edge == True:\n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 1)\n",
    "    else: \n",
    "        windows = windows.reshape(windows.shape[0], windows.shape[1], windows.shape[2], 3)\n",
    "    predictions = model.predict(windows)\n",
    "    \n",
    "    clone = img.copy() \n",
    "    clone2 = img.copy()\n",
    "    for idx, pred in enumerate(predictions): \n",
    "        if pred[1] == 1 or pred[2] == 1: \n",
    "            startx, starty, endx, endy = locations[idx]\n",
    "            cv2.rectangle(clone, (startx, starty), (endx, endy), (0,0,255), 2)\n",
    "            break\n",
    "            \n",
    "    no_sum = predictions[:,0].sum()\n",
    "    pistol_sum = predictions[:,1].sum()\n",
    "    rifle_sum = predictions[:,2].sum() \n",
    "    sum_array = np.array([no_sum, pistol_sum, rifle_sum])\n",
    "    print(sum_array)\n",
    "#     clone = img.copy()\n",
    "#     clone2 = img.copy()\n",
    "#     print(np.argmax(sum_array))\n",
    "#     cat_predictions = predictions[:,np.argmax(sum_array)]\n",
    "#     pred_max_idx = np.argmax(cat_predictions)\n",
    "#     pred_max = cat_predictions[pred_max_idx]\n",
    "    \n",
    "#     pred_max_window = locations[pred_max_idx]\n",
    "#     startx, starty, endx, endy = pred_max_window\n",
    "\n",
    "\n",
    "#     cv2.rectangle(clone, (startx, starty), (endx, endy),  (0,0,255),2)\n",
    "#     cat = category_dict[np.argmax(sum_array)]\n",
    "#     text = f'{cat}'\n",
    "#     cv2.putText(clone, text, (startx, starty), cv2.FONT_HERSHEY_SIMPLEX, .45, (0,0,255),2)\n",
    "   \n",
    "\n",
    "    cv2.imshow(f'Test', np.hstack([clone, clone2]))\n",
    "    cv2.waitKey(0)\n",
    "    ss.clear()\n",
    "\n",
    "\n",
    "    return predictions\n",
    "base_path = '../Tests/Photos'\n",
    "edge = True\n",
    "if edge == True: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 1)\n",
    "else: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights2.h5')\n",
    "\n",
    "for file in os.listdir(base_path): \n",
    "    img = get_img_prediction_bounding_box(f'{base_path}/{file}', normal_model, var.norm_dimension, edge = edge)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../Tests/Photos'\n",
    "edge = True\n",
    "if edge == True: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 1)\n",
    "else: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights2.h5')\n",
    "\n",
    "\n",
    "for file in os.listdir(base_path): \n",
    "    if file == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    full_path = f'{base_path}/{file}'\n",
    "    if edge == True: \n",
    "        img = func.get_image_value(full_path, var.norm_dimension, edge = True)   \n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
    "    else:\n",
    "        img = func.get_image_value(full_path, var.norm_dimension) \n",
    "        print(img.shape)\n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = normal_model.predict(img)[0]\n",
    "    print(f'{file}\\t\\t{np.argmax(pred)}\\t\\t{pred.max()}\\t\\t{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../Tests/Photos'\n",
    "edge = False\n",
    "if edge == True: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 1)\n",
    "else: \n",
    "    dim = (x_train.shape[1], x_train.shape[2], 3)\n",
    "    \n",
    "normal_model = get_conv_model_normal(dim)\n",
    "normal_model.load_weights('../models/CNN-ModelCheckpointWeights1.h5')\n",
    "\n",
    "\n",
    "for file in os.listdir(base_path): \n",
    "    if file == '.ipynb_checkpoints':\n",
    "        continue\n",
    "    full_path = f'{base_path}/{file}'\n",
    "    if edge == True: \n",
    "        img = func.get_image_value(full_path, var.norm_dimension, edge = True)   \n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 1)\n",
    "    else:\n",
    "        img = func.get_image_value(full_path, var.norm_dimension) \n",
    "        print(img.shape)\n",
    "        img = img.reshape(1, img.shape[0], img.shape[1], 3)\n",
    "    pred = normal_model.predict(img)[0]\n",
    "    print(f'{file}\\t\\t{np.argmax(pred)}\\t\\t{pred.max()}\\t\\t{pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_img_prediction_bounding_box('../Tests/Photos/Pistol.jpg', normal_model, var.norm_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "\n",
    "model 3\n",
    "\n",
    "if edge == True: \n",
    "    img = func.get_image_value(full_path, var.norm_dimension, edge = True)   \n",
    "    img = np.stack((img,)*3, axis = -1)\n",
    "else:\n",
    "    img = func.get_image_value(full_path, var.norm_dimension)    \n",
    "    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(img, normal_model.predict, top_labels = 5, hide_color = 0, \n",
    "                                         num_samples = 2000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only = False,\n",
    "                                           num_features = 10, hide_rest = False)\n",
    "plt.imshow(mark_boundaries(temp/2 + .5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
